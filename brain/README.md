# This is Jordan's brain
## 概述
好吧，这个就是Jordan's brain了，也就是Jordan最核心的部分，
主要就是用强化学习算法来让Jordan学习如何play Gomoku，嗯，感觉
自己其实只做了一点微小的工作，毕竟没做啥原创性工作，嗯，大致说一下吧
算法上主要就是蒙特卡洛树搜索和卷积神经网络CNN，简单说下蒙特卡洛树搜索
这个包括四个part，选择，拓展，模拟和反向传播，简而言之在Gomoku当中
这四个part就是寻找当前状态可以达到的状态，然后拓展到（DFS）这些状态（主要是那些胜率较高的状态
，如果低于某个阙值，实际上就将该状态剪枝了），接着反复执行，直到达到目标状态
（就是出现五个子连在一起的状态）此时先更新这一状态的胜率，然后反向传播至所有经历过的装态
然后学习的过程其实就是使用当前模型不断地用蒙特卡洛搜索自己和自己下，产生了大量数据，数据就是局面和对应的胜率
然后把数据输入CNN进行拟合就好了，CNN的结构是一个3层的网络，输入层是9x9x4，其中前两个9顾名思义，后面一个4指的是最近4步的局势，
然后两层卷积层是做了两次3*3的卷积，后面再加一个全连接层，最后CNN的输出就是输入局面下的胜率，简单来说就是这样把，其实
网络结构也不是很复杂，自己做的事情其实就是再原始的别人写的8x8的模型的基础上改了下模型，
然后蒙特卡洛搜索直接用的别人代码。。。。

## 运行
跑着玩的话直接 python main_start.py就好拉。。。
