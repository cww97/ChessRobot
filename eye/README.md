# This is Jordan's eye
### HY

## 概述

视觉识别的目标是通过用摄像头以固定时间间隔对棋盘进行拍摄，并将当前图片
与前一状态进行对比从而得到玩家落子的位置。

## 图像获取

使用了微视的工业用摄像头，用在官方给出的sdk基础上用C#二次开发
了一个可以以一定时间间隔拍摄图像的后台程序，将得到的照片保存
在了本项目目录下的camera文件夹中

## 算法实现

### 实现目标
输出获取到的图像，在确定发生玩家落子的条件下，用向量形式输出玩家落子的位置

### 初始想法

先抠出图片中的棋盘区域，然后将棋盘区域分割为9 * 9
个子区域，然后对每个子区域中的像素点进行加和平均，并且设定两个阈值，当大于上限阈值时判定为白子，小于下限阈值时，判定为黑子，
得到描述局势的矩阵，将先后两次矩阵做差，得到落子位置(返回差矩阵上非零数的行和列)

### 初始想法产生的问题

由于实际拍摄的照片中，会因为现实中的灯光或者遮盖物以及棋盘本身的反光，导致棋盘的每个区域的光照强度有较大差异，
因此使用的固定的两个阈值会难以分辨落了白子和未落子这两种情况，因为在反光或者部分曝光过度的区域，
算出来的像素点加和平均完全有可能超过上限阈值

### 解决思路

因为区域亮度不平衡主要影响在了识别落了白子和未落子这两种情况，因此
解决这个问题的关键在于将三值化问题转换为二值化问题


### 具体解决方法

首先将当前图片与前一状态图片都进行中值模糊以此来降低噪声，然后将两张图片做自适应阈值二值化，得到
各自的线框图，然后将两张线框图做异或操作取出不同区域，并对结果再一次做中值模糊降噪，于是就
得到了当前落子的位置，在根据这一位置信息，与原图进行比对，得到落子方以及落子的位置

### 识别算法在具体对弈流程中的运用

使用了一个简单的忙等待，通过以固定时间间隔不断地读取当前图片
将其与前一状态进行对比，如果没有找出落子区域，则继续忙等待，若找到落子区域，如果落子的为机器人，
则更新状态，若落子的为人，则返回落子位置，并更新状态。

### 依然存在的问题

当前算法虽然可以有效解决光照不均衡问题，但是对于摄像头或者棋盘抖动产生的识别误差依然无法避免，
未来可以用深度学习来做目标检测以此来规避以上所有问题，使得算法的可靠性得到较大提升

## 实现的接口说明

- 以下述的图像处理过程都放在了opencv_process.py文件中
1. image_process(img, last_img)
输入前后两张图片，用image形式返回落子区域
2. cut_process(input_image)
输入图片，以image形式返回棋盘区域
3. get_input_result(result_image, chessboard_image)
输入中得到的image_process中得到的result，将其与经过cut_process处理后的原图进行比照
返回落子方和落子位置

- 以下的图像处理过程放在了myeye.py文件中
get_input(old_last)
封装了上述过程，输入初始状态，根据摄像头定时返回的照片得到玩家落子位置